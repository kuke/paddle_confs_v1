#!/usr/bin/env python
import math

learning_rate = get_config_arg('learning_rate', float, 0.001)
fix_layer = get_config_arg('fix_layer', int, 1)
batch_size = get_config_arg('batch_size', int, 200)

# True for training, False for testing
predict_filelist = get_config_arg('predict_filelist', str, '')
train_filelist = get_config_arg('train_filelist', str, '')
test_filelist = get_config_arg('test_filelist', str, '')

if train_filelist:
    TrainData(ProtoData(files=train_filelist))
    has_label = True

if predict_filelist:
    TestData(ProtoData(files=predict_filelist))
    has_label = False
elif test_filelist:
    TestData(ProtoData(files=test_filelist))
    has_label = True

default_initial_std(0.1)
default_decay_rate(0)

if has_label:
    Inputs("word", "ws", "ner")
    if test_filelist:
        Outputs("crf_decoding_output")
    else:
        Outputs("crf")
else:
    Inputs("word", "ws")
    Outputs("crf_decoding")

number_classes = 37
num_word = 4358
num_pos = 45
num_chunk = 17
num_caps = 2
num_ws = 2

word_dim = 50
caps_dim = 5
context_length = 5
hidden_dim = 300

DataLayer(
    name="word",
    size=num_word, )

DataLayer(
    name="ws",
    size=num_ws, )

if has_label:
    DataLayer(name="ner", size=number_classes)

MixedLayer(
    name="word_embedding",
    size=word_dim,
    bias=False,
    inputs=TableProjection(
        "word", initial_std=math.sqrt(1. / word_dim), learning_rate=fix_layer),
)

MixedLayer(
    name="ws_embedding",
    size=5,
    bias=False,
    inputs=TableProjection("ws", initial_std=0.01))

context_dim = context_length * (word_dim + caps_dim)

ConcatenateLayer(
    name="word_caps_vector", inputs=["word_embedding", "ws_embedding"])

MixedLayer(
    name="hidden1",
    size=hidden_dim,
    active_type="tanh",
    bias=True,
    inputs=[
        FullMatrixProjection(
            "word_caps_vector", initial_std=math.sqrt(1. / context_dim)),
    ])

RecurrentLayer(
    name="rnn1-1",
    active_type="relu",
    bias=Bias(initial_std=0),
    inputs=Input("hidden1", initial_std=0, learning_rate=1))

RecurrentLayer(
    name="rnn1-2",
    active_type="relu",
    reversed=True,
    bias=Bias(initial_std=0),
    inputs=Input("hidden1", initial_std=0, learning_rate=1))

MixedLayer(
    name="hidden2-1",
    size=hidden_dim,
    active_type="stanh",
    inputs=[
        FullMatrixProjection("hidden1"),
        FullMatrixProjection("rnn1-1", initial_std=0, learning_rate=1)
    ])

MixedLayer(
    name="hidden2-2",
    size=hidden_dim,
    active_type="stanh",
    inputs=[
        FullMatrixProjection("hidden1"),
        FullMatrixProjection("rnn1-2", initial_std=0, learning_rate=1)
    ])

RecurrentLayer(
    name="rnn2-1",
    active_type="relu",
    reversed=True,
    bias=Bias(initial_std=0),
    inputs=Input("hidden2-1", initial_std=0, learning_rate=1))

RecurrentLayer(
    name="rnn2-2",
    active_type="relu",
    reversed=False,
    bias=Bias(initial_std=0),
    inputs=Input("hidden2-2", initial_std=0, learning_rate=1))

MixedLayer(
    name="hidden3",
    size=hidden_dim,
    bias=True,
    active_type="stanh",
    inputs=[
        FullMatrixProjection("hidden2-1"),
        FullMatrixProjection("rnn2-1", initial_std=0, learning_rate=1),
        FullMatrixProjection("hidden2-2"),
        FullMatrixProjection("rnn2-2", initial_std=0, learning_rate=1)
    ])

MixedLayer(
    name="output",
    size=number_classes,
    bias=False,
    inputs=[
        FullMatrixProjection(
            "hidden3", initial_std=math.sqrt(1. / hidden_dim))
    ])

if has_label:
    CRFLayer(
        name="crf",
        size=number_classes,
        inputs=[Input("output", parameter_name="crfw"), "ner"])

Layer(
    name="crf_decoding",
    type="crf_decoding",
    size=number_classes,
    inputs=[Input("output", parameter_name="crfw")] + (["ner"]
                                                       if has_label else []))

if test_filelist:
    Layer(
        name="crf_decoding_output",
        type="crf_decoding",
        size=number_classes,
        inputs=[Input("output", parameter_name="crfw")])

if has_label:
    Evaluator(
        name="error",
        type="sum",
        inputs="crf_decoding", )

    Evaluator(
        name="ner_f1",
        type="chunk",
        inputs=["crf_decoding", "ner"],
        chunk_scheme="IOB",
        num_chunk_types=(number_classes - 1) / 2, )

default_momentum(0.1)

Settings(
    algorithm='sgd',
    batch_size=batch_size,
    learning_method='momentum',
    ada_epsilon=0.0001,
    ada_rou=0.95,
    average_window=0.5,
    max_average_window=2500,
    learning_rate=learning_rate,
    learning_rate_decay_a=5e-7,
    learning_rate_decay_b=0.5,
    l1weight=0,
    l2weight=100,
    c1=0.0001,
    backoff=0.5,
    owlqn_steps=100,
    max_backoff=5,
    usage_ratio=1.)
