#!/usr/bin/env python
# coding: utf-8

from paddle.trainer_config_helpers import *
import math
Settings(
    algorithm='sgd',
    learning_rate=0.0001,
    batch_size=4000,
    average_window=0.0,
    max_average_window=0,
    learning_rate_decay_a=0,
    learning_rate_decay_b=0, )

word_emb_dim = 256
hidden_dim = 256
default_decay_rate(8e-4)
default_initial_std(1 / math.sqrt(hidden_dim) / 10.0)
dict_path = "./idict.sort.100w.1"
dict_len_basic = len(open(dict_path).read().strip().split('\n')) + 1
TrainData(
    PyData(
        files='train.list',
        load_data_module='dataprovider',
        load_data_object='processData',
        load_data_args=dict_path, ))

Layer(type='data', name="query", size=dict_len_basic)
Layer(type='data', name="title", size=dict_len_basic)
Layer(type='data', name="score", size=1)

Layer(
    name="emb_q",
    type="mixed",
    size=256,
    active_type="linear",
    inputs=TableProjection(
        "query", parameter_name="emb.w", decay_rate=8e-4, learning_rate=10),
    bias=False)
Layer(
    name="emb_t",
    type="mixed",
    size=256,
    active_type="linear",
    inputs=TableProjection(
        "title", parameter_name="emb.w", decay_rate=8e-4, learning_rate=10),
    bias=False)
Layer(
    inputs=[Input('emb_q')],
    name='avemb_q',
    bias=False,
    active_type="tanh",
    type="average",
    average_strategy="sum",
    trans_type="seq")
Layer(
    inputs=[Input('emb_t')],
    name='avemb_t',
    bias=False,
    active_type="tanh",
    type="average",
    average_strategy="sum",
    trans_type="seq")
Layer(
    inputs=[Input(
        "avemb_q",
        parameter_name="_hidden_query.w", )],
    bias=Bias(parameter_name="_hidden_query.bias"),
    name="hidden_query",
    active_type="tanh",
    type="fc",
    size=256)
Layer(
    inputs=[Input(
        "avemb_t",
        parameter_name="_hidden_title.w", )],
    bias=Bias(parameter_name="_hidden_title.bias"),
    name="hidden_title",
    active_type="tanh",
    type="fc",
    size=256)

CosSimLayer(
    name='output',
    inputs=["hidden_query", "hidden_title"], )
Layer(
    name="cost",
    type="lambda_cost",
    NDCG_num=6,
    max_sort_size=-1,
    inputs=["output", "score"])
Inputs("query", "title", "score")
Outputs("cost")
